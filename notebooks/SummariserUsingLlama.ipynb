{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install langchain_huggingface\n","!pip install langchain_community\n","!pip install gputil\n","!pip install PyMuPDF\n","!pip install sentence-transformers\n","!pip install ctransformers\n","!pip install faiss-cpu\n","!pip install numpy==1.26.4\n","!pip install langchain_milvus\n","!pip install pymilvus"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from langchain_huggingface import HuggingFaceEmbeddings\n","from langchain_community.vectorstores import FAISS\n","from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_core.prompts import PromptTemplate\n","from langchain_community.llms import LlamaCpp\n","from langchain_community.chat_models import ChatLlamaCpp\n","from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n","import os\n","import json\n","import warnings\n","import logging\n","import time\n","import psutil\n","import GPUtil\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO)  # Adjust level as needed\n","logger = logging.getLogger(__name__)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%pip install arxiv  llama-cpp-python"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from arxiv import Search\n","\n","\n","\n","# Initialize Llama CPP\n","llm = LlamaCpp(\n","            model_path=\"/kaggle/input/meta-llama-3-8b-gguf/llama3-8b-instruct-Q5_K_M.gguf\",\n","            n_ctx=2048,\n","            n_gpu_layers=-1,\n","            verbose=True,\n","            seed=1000,\n","            temperature=0,\n","        )\n","\n","\n","def fetch_arxiv_data(query):\n","    # Fetching papers from arxiv.org\n","    search = Search(\n","        query=query,\n","        max_results=5, \n","        \n","    )\n","    papers = list(search.results())\n","    sorted_papers = sorted(papers, key=lambda paper: paper.published, reverse=True)  # Sort by publication date\n","\n","    return sorted_papers\n","\n","    \n","\n","def generate_summary(query):\n","    # Fetch papers\n","    papers = fetch_arxiv_data(query)\n","\n","    # Process each paper\n","    summaries = []\n","    for paper in papers:\n","        title = paper.title\n","        abstract = paper.summary\n","\n","\n","        # Generate detailed content using Llama CPP\n","        prompt_template = PromptTemplate(template=\"Provide a detailed overview based on the title: {title}\", input_variables=['title'])\n","        prompt_det = prompt_template.format(title=title)\n","        detailed_content = llm.invoke(prompt_det)\n","\n","\n","        summary_prompt = PromptTemplate(template=\"Summarize the following text: {title}. {abstract}. {detailed_content}\", input_variables=['title', 'abstract', 'detailed_content'])\n","        prompt_summary =  summary_prompt.format(title = title, abstract = abstract, detailed_content = detailed_content)\n","        prompt_sum = prompt_summary\n","\n","        # Generate summary using Llama CPP\n","        summary = llm.invoke(prompt_sum)\n","\n","        summaries.append({\n","            'title': title,\n","            'original_abstract': abstract,\n","            'generated_summary': summary\n","        })\n","\n","    return summaries\n","\n","# Example usage:\n","query = \"Naruto Uzumaki\"\n","summaries = generate_summary(query)\n","\n","for summary in summaries:\n","    print(f\"Title: {summary['title']}\")\n","    print(f\"Original Abstract: {summary['original_abstract']}\")\n","    print(f\"Generated Summary: {summary['generated_summary']}\")\n","    print(\"\\n\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4880117,"sourceId":8230136,"sourceType":"datasetVersion"},{"datasetId":5235908,"sourceId":8724768,"sourceType":"datasetVersion"},{"datasetId":5249561,"sourceId":8743213,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
